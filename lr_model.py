# -*- coding: utf-8 -*-
"""lr_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v8-Js6CvEmexUDaE8ISlDyvdl3fUVE6F
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split
from sklearn.metrics import confusion_matrix, precision_recall_curve, auc, roc_auc_score, roc_curve, recall_score, classification_report


# %matplotlib inline

data = pd.read_csv("creditcard.csv")
data.head()

## Directly normalize 'Amount'
data_1 = data.copy()

data_1['scaled_amount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))
data_1 = data_1.drop(['Amount','Time'],axis=1)

## Log transform and normalize 'Amount'
data_2 = data.copy()

data_2['logAmount'] = np.log1p(data['Amount'])
data_2['normLogAmount'] = StandardScaler().fit_transform(data_2['logAmount'].values.reshape(-1, 1))
data_2 = data_2.drop(['Time', 'Amount', 'logAmount'], axis=1)

X1 = data_1.loc[:, data_1.columns != 'Class']
y1 = data_1.loc[:, data_1.columns == 'Class']

X_train_rf, X_test_rf1, y_train_rf, y_test_rf1 = train_test_split(
    X1, y1,
    test_size=0.3,
    random_state=0,
    stratify=y1
)


# Undersample
fraud_indices = y_train_rf[y_train_rf['Class']==1].index
normal_indices = y_train_rf[y_train_rf['Class']==0].index

random_normal_indices = np.random.choice(normal_indices, size=len(fraud_indices), replace=False)
under_sample_indices = np.concatenate([fraud_indices, random_normal_indices])


X_train_lr_us_norm = X_train_rf.loc[under_sample_indices]
y_train_lr_us_norm = y_train_rf.loc[under_sample_indices]
X_train_lr_bal_norm = X_train_rf
y_train_lr_bal_norm = y_train_rf
X_test_lr1 = X_test_rf1
y_test_lr1 = y_test_rf1

X2 = data_2.loc[:, data_2.columns != 'Class']
y2 = data_2.loc[:, data_2.columns == 'Class']

X_train_rf, X_test_rf2, y_train_rf, y_test_rf2 = train_test_split(
    X2, y2,
    test_size=0.3,
    random_state=0,
    stratify=y2
)

# Undersample
fraud_indices = y_train_rf[y_train_rf['Class']==1].index
normal_indices = y_train_rf[y_train_rf['Class']==0].index

random_normal_indices = np.random.choice(normal_indices, size=len(fraud_indices), replace=False)
under_sample_indices = np.concatenate([fraud_indices, random_normal_indices])

X_train_lr_us_log = X_train_rf.loc[under_sample_indices]
y_train_lr_us_log= y_train_rf.loc[under_sample_indices]
X_train_lr_bal_log = X_train_rf
y_train_lr_bal_log= y_train_rf
X_test_lr2 = X_test_rf2
y_test_lr2 = y_test_rf2

def select_best_C_by_auprc(x_train_data, y_train_data, c_param_range=[0.01,0.1,1,10,100], n_splits=5, random_state=0):

    fold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)

    results_table = pd.DataFrame(index=range(len(c_param_range)), columns=['C_parameter', 'Mean_AUPRC'])
    results_table['C_parameter'] = c_param_range

    for j, c_param in enumerate(c_param_range):
        auprcs = []
        for train_index, val_index in fold.split(x_train_data, y_train_data):
            X_train_fold = x_train_data.iloc[train_index,:]
            y_train_fold = y_train_data.iloc[train_index,:].values.ravel()
            X_val_fold = x_train_data.iloc[val_index,:]
            y_val_fold = y_train_data.iloc[val_index,:].values.ravel()

            lr = LogisticRegression(C=c_param, penalty='l1', solver='liblinear')
            lr.fit(X_train_fold, y_train_fold)

            y_proba = lr.predict_proba(X_val_fold)[:,1]
            precision, recall, _ = precision_recall_curve(y_val_fold, y_proba)
            fold_auprc = auc(recall, precision)
            auprcs.append(fold_auprc)

        results_table.loc[j, 'Mean_AUPRC'] = np.mean(auprcs)
        print(f"C={c_param}: Mean AUPRC = {np.mean(auprcs):.4f}")

    best_c = results_table.loc[results_table['Mean_AUPRC'].idxmax(), 'C_parameter']
    print("*********************************************************************************")
    print(f"Best C parameter (Max Mean AUPRC) = {best_c}")
    print("*********************************************************************************")

    return best_c, results_table

##------
best_c1, rt1 = select_best_C_by_auprc(X_train_lr_us_norm,y_train_lr_us_norm)

lr_us_norm = LogisticRegression(C = best_c1, penalty = 'l1', solver='liblinear', random_state=0)
lr_us_norm.fit(X_train_lr_us_norm, y_train_lr_us_norm.values.ravel())

##------
best_c2, rt2 = select_best_C_by_auprc(X_train_lr_us_norm,y_train_lr_us_norm)

lr_us_log = LogisticRegression(C = best_c2, penalty = 'l1', solver='liblinear', random_state=0)
lr_us_log.fit(X_train_lr_us_log, y_train_lr_us_log.values.ravel())

def select_best_C_by_auprc_weighted(x_train_data, y_train_data, c_param_range=[0.01, 0.1, 1, 10, 100], n_splits=5, random_state=0):

    fold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)

    results_table = pd.DataFrame(index=range(len(c_param_range)), columns=['C_parameter', 'Mean_AUPRC'])
    results_table['C_parameter'] = c_param_range

    for j, c_param in enumerate(c_param_range):
        auprcs = []
        for train_index, val_index in fold.split(x_train_data, y_train_data):

            X_train_fold = x_train_data.iloc[train_index,:]
            y_train_fold = y_train_data.iloc[train_index,:].values.ravel()
            X_val_fold = x_train_data.iloc[val_index,:]
            y_val_fold = y_train_data.iloc[val_index,:].values.ravel()

            lr = LogisticRegression(C=c_param, penalty='l1', solver='liblinear', class_weight='balanced', max_iter=1000, random_state=random_state)
            lr.fit(X_train_fold, y_train_fold)

            y_proba = lr.predict_proba(X_val_fold)[:,1]
            precision, recall, _ = precision_recall_curve(y_val_fold, y_proba)
            fold_auprc = auc(recall, precision)
            auprcs.append(fold_auprc)

        results_table.loc[j, 'Mean_AUPRC'] = np.mean(auprcs)
        print(f"C={c_param}: Mean AUPRC = {np.mean(auprcs):.4f}")

    best_c = results_table.loc[results_table['Mean_AUPRC'].idxmax(), 'C_parameter']
    print("*********************************************************************************")
    print(f"Best C parameter (Max Mean AUPRC) = {best_c}")
    print("*********************************************************************************")

    return best_c, results_table

##------
best_c_weighted1, rt_weighted = select_best_C_by_auprc_weighted(X_train_lr_bal_norm, y_train_lr_bal_norm)

lr_bal_norm = LogisticRegression(
    C = best_c_weighted1,
    penalty = 'l1',
    solver='liblinear',
    class_weight='balanced',
    random_state=0
)

lr_bal_norm.fit(X_train_lr_bal_norm, y_train_lr_bal_norm.values.ravel())

##------
best_c_weighted2, rt_weighted = select_best_C_by_auprc_weighted(X_train_lr_bal_log, y_train_lr_bal_log)

lr_bal_log = LogisticRegression(
    C = best_c_weighted2,
    penalty = 'l1',
    solver='liblinear',
    class_weight='balanced',
    random_state=0
)

lr_bal_log.fit(X_train_lr_bal_log, y_train_lr_bal_log.values.ravel())

def plot_multiple_pr_curves(models, X_tests, y_tests, labels):
    plt.figure(figsize=(10,6))

    for model, X_test, y_test, label in zip(models, X_tests, y_tests, labels):
        y_proba = model.predict_proba(X_test)[:,1]
        precision, recall, _ = precision_recall_curve(y_test, y_proba)
        auprc = auc(recall, precision)
        plt.plot(recall, precision, label=f"{label} (AUPRC={auprc:.4f})")

    plt.xlabel("Recall")
    plt.ylabel("Precision")
    plt.title("Comparison of Precision-Recall Curves")
    plt.legend()
    plt.grid(True)
    plt.show()


models = [lr_us_norm, lr_us_log, lr_bal_norm, lr_bal_log]
X_tests = [X_test_lr1, X_test_lr2, X_test_lr1, X_test_lr2]
y_tests = [y_test_lr1, y_test_lr2, y_test_lr1, y_test_lr2]
labels = ["Undersample Norm", "Undersample Log", "Balanced Norm", "Balanced Log"]

plot_multiple_pr_curves(models, X_tests, y_tests, labels)